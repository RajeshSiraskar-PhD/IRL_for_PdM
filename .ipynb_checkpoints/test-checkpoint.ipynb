{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm # Progress bar\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# RL libraries\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# CH-AI Imitation libraries\n",
    "from imitation.util.util import make_vec_env\n",
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "\n",
    "# Custom libraries\n",
    "# from milling_tool_env import MillingTool\n",
    "from utilities import downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'NUAA_W1.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUAA_DATA_FILE = 'NUAA_W1.csv'\n",
    "training_expts = ['W1']\n",
    "wear_thresholds = {'W1':0.229}\n",
    "WEAR_THRESHOLD = wear_thresholds['W1']\n",
    "\n",
    "# training_expts = ['W1', 'W2','W3','W4']\n",
    "# wear_thresholds = {'W1':0.229, 'W2':0.12, 'W3':0.12, 'W4':0.2} # Based on 'observation'\n",
    "\n",
    "SAMPLING_RATE = 1\n",
    "ADD_NOISE = 0\n",
    "\n",
    "column_names = ['timestamp', 'vibration_x', 'vibration_y', 'force_z', 'tool_wear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LAMBDA = 0.01\n",
    "\n",
    "NO_ACTION = 0\n",
    "REPLACE = 1\n",
    "\n",
    "MAX_OP_CYCLES = 0.0 # \n",
    "\n",
    "time_since_last_replacement = 0\n",
    "\n",
    "a_time = []\n",
    "a_cost = []\n",
    "a_action_recommended = []\n",
    "a_actions = []\n",
    "a_action_text = []\n",
    "a_rul = []\n",
    "a_rewards = []\n",
    "a_replacements = []\n",
    "a_time_since_last_replacement = []\n",
    "\n",
    "class MillingToolEnv_NUAA(gym.Env):\n",
    "    \"\"\"A Milling Tool RUL environment for OpenAI gym\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df=None, max_op_cycles = 0.0, tool_failure_thresholds=[0.0], tool_failure_times=[0.0]):        \n",
    "        # super(MillingToolEnv_NUAA, self).__init__()\n",
    "        \n",
    "        print(df)\n",
    "        # Machine data frame properties\n",
    "        if df is not None:\n",
    "            self.df = df\n",
    "            self.records = len(self.df.index)\n",
    "            print(f'\\n\\n** -- NUAA Milling Tool Wear environment. Records {self.records} -- **\\n\\n')\n",
    "        else:\n",
    "            print(f'\\n\\n** -- NUAA Milling Tool Wear environment. Error: NO TOOL WEAR DATA SUPPLIED !! -- **\\n\\n')\n",
    "            self.records = 0 # Indicates - no dataframe\n",
    "\n",
    "        # Initialization\n",
    "        self.current_time_step = 0  # Initial state, this will be INCREMENTED every step\n",
    "        # self.max_op_cycles = max_op_cycles    # Store max life (max RUL) of tool\n",
    "        self.tool_failure_thresholds = tool_failure_thresholds # Product quality unacceptable - must replace\n",
    "        self.tool_failure_times = tool_failure_times\n",
    "        # self.rul = self.df.loc[self.current_time_step, 'RUL']   # Initial RUL, this will be DECREMENTED every step. Also the DONE condition\n",
    "        # self.rul = self.starting_rul \n",
    "        self.time_at_replacement = 0\n",
    "        self.time_since_last_replacement = 0\n",
    "        self.maintenance_cost = 0.0        \n",
    "        self.replacement_events = 0\n",
    "        self.reward = 0.0\n",
    "        self.current_action = NO_ACTION\n",
    "        \n",
    "        # Observation vector: Time, vibration, force\n",
    "        # column_names = ['timestamp', 'vibration_x', 'vibration_y', 'force_z', 'tool_wear', 'RUL', 'ACTION_CODE']\n",
    "        # Observation space upper limits\n",
    "        high = np.array(\n",
    "            [\n",
    "                self.records, # Max time\n",
    "                1.0,          # Max. vibration_x\n",
    "                1.0,          # Max. vibration_y\n",
    "                1.0,          # Max. force_z\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        # observation space lower limits\n",
    "        low = np.array(\n",
    "            [\n",
    "                0,            # Min. time\n",
    "                -1.0,         # Min. vibration_x\n",
    "                -1.0,         # Min. vibration_y\n",
    "                -1.0,         # Min. force_z\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        \n",
    "        self.action_space = spaces.Discrete(2) # Normal and replace\n",
    "        self.observation_space = spaces.Box(low, high, dtype=np.float32)\n",
    "        self.state = None\n",
    "        print(f'Milling tool environment initiated. Number of records: {self.records}')\n",
    "            \n",
    "    def _next_observation(self):\n",
    "        frame = np.array([\n",
    "            self.df.loc[self.current_time_step, 'timestamp'],\n",
    "            self.df.loc[self.current_time_step, 'vibration_x'],\n",
    "            self.df.loc[self.current_time_step, 'vibration_y'],\n",
    "            self.df.loc[self.current_time_step, 'force_z'],\n",
    "        ])\n",
    "        \n",
    "        # Append additional data and scale each value to between 0-1\n",
    "        obs = frame.flatten()\n",
    "        return obs\n",
    "\n",
    "    def _take_action(self, action):\n",
    "\n",
    "        if action == NO_ACTION: # Normal state\n",
    "            # 1% reduction in life\n",
    "            self.maintenance_cost += 0.1            \n",
    "            self.current_time_step += 1\n",
    "            action_text = 'None'\n",
    "                        \n",
    "        elif action == REPLACE:\n",
    "            # Replace the tool -- Starting RUL will now be random but around the RUL we have\n",
    "            self.maintenance_cost += 10.0            \n",
    "            self.replacement_events += 1            \n",
    "            # self.time_since_last_replacement = self.current_time_step - self.time_at_replacement\n",
    "            # self.time_at_replacement = self.current_time_step\n",
    "            self.time_since_last_replacement = self.current_time_step\n",
    "            # self.current_time_step = 0\n",
    "            a_time_since_last_replacement.append(self.time_since_last_replacement)\n",
    "            print(f' ============ Time since last replacement: {self.time_since_last_replacement} ==============')            \n",
    "            action_text = '* REPLACE *' \n",
    "                    \n",
    "        self.reward = (self.current_time_step + 1) / (self.maintenance_cost+LAMBDA)\n",
    "        \n",
    "        a_actions.append(action)\n",
    "        a_action_text.append(action_text)\n",
    "\n",
    "        print('{0:<20} | RUL: {1:>8.2f} | Cost: {2:>8.2f} | Reward: {3:>12.3f}'.format(action_text, self.rul, self.maintenance_cost, self.reward))\n",
    "                 \n",
    "        self.state = (self.rul, self.maintenance_cost, action)\n",
    "\n",
    "\n",
    "    ## Step function\n",
    "    #  This is a time step:\n",
    "    #   1. Take action, and assign reward (calls _take_action())\n",
    "    #   2. Increment the time-step i.e. self.current_time_step ++\n",
    "    #   3. Decrease life i.e. self.rul = next lower RUL\n",
    "    def step(self, action):\n",
    "        print ('1. ** HERE IN STEP ** ')   \n",
    "        ## Find the RUL\n",
    "        # self.rul = self.df.loc[self.current_time_step, 'RUL']\n",
    "        ## For this current time - take action\n",
    "        self._take_action(action)\n",
    "        reward = self.reward\n",
    "        \n",
    "        print ('2. ** HERE IN STEP ** ')   \n",
    "        ## Check for termination\n",
    "        #  Records over\n",
    "        if self.current_time_step >= (self.records-1):\n",
    "            print ('3.1. ** HERE IN STEP ** ')\n",
    "            self.current_time_step = 0\n",
    "            done = True\n",
    "        elif self.rul <= 1: # Less-than-equal 0 (or near zero)\n",
    "            print ('3.2. ** HERE IN STEP ** ')\n",
    "            done = True\n",
    "        else:\n",
    "            print ('3.3. ** HERE IN STEP ** ')\n",
    "            done = False\n",
    "\n",
    "        print ('3-OUT. ** HERE IN STEP ** ') \n",
    "        ## For this current time - record all values\n",
    "        a_time.append(self.current_time_step)\n",
    "        a_rewards.append(self.reward)\n",
    "        a_rul.append(self.rul)\n",
    "        a_cost.append(self.maintenance_cost)\n",
    "        # a_events.append(self.maintenance_events)\n",
    "        a_replacements.append(self.replacement_events)\n",
    "        print ('4. ** HERE IN STEP ** ')\n",
    "        # From database extract recommended action\n",
    "        recommended_action = self.df.loc[self.current_time_step, 'ACTION_CODE']\n",
    "\n",
    "        a_action_recommended.append(recommended_action)\n",
    "\n",
    "        ## Now, increment current time step\n",
    "        self.current_time_step += 1\n",
    "        self.time_since_last_replacement += 1\n",
    "        obs = self._next_observation()\n",
    "        \n",
    "        return obs, reward, done, {}\n",
    "\n",
    "     # $$ New Gymnasium format\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # We need the following line to seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Reset environment variables and stats.\n",
    "        self.current_time_step = 0\n",
    "        self.reward = 0.0\n",
    "        self.rul = self.df.loc[self.current_time_step, 'RUL']\n",
    "        # print('\\n --- RESET. Starting RUL = ', self.rul)\n",
    "\n",
    "        # Reset the state of the environment to an initial state\n",
    "        self.time_since_last_replacement = 0\n",
    "        self.maintenance_cost = 0.0\n",
    "        # self.maintenance_events = 0\n",
    "        self.replacement_events = 0\n",
    "        self.reward = 0.0\n",
    "        self.current_action = NO_ACTION\n",
    "\n",
    "        ## For this current time - record all values\n",
    "        a_time.append(self.current_time_step)\n",
    "        \n",
    "\n",
    "        a_replacements.append(self.replacement_events)\n",
    "        a_rewards.append(self.reward)\n",
    "        a_rul.append(self.rul)\n",
    "        a_cost.append(self.maintenance_cost)\n",
    "        # print(120*'=')\n",
    "        # print(f'=== RESET: Maintenance cost reset: {self.maintenance_cost} Time since last replacement: {self.time_since_last_replacement}====================')\n",
    "        # print(120*'=')\n",
    "        # a_events.append(self.maintenance_events)\n",
    "\n",
    "        # Reset done before returning\n",
    "        done = False\n",
    "\n",
    "        print(' -- RESET -- ')\n",
    "        # return np.array(self.state, dtype=np.float32)\n",
    "        return self.state\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        # Render the environment to the screen\n",
    "        RUL = self.rul\n",
    "        \n",
    "        # print('>> {0:<20} | RUL: {1:>8.2f} | Cost: {2:>8.2f} | Reward: {3:>12.3f}'.\n",
    "            #   format(self.current_action, self.rul, self.maintenance_cost, self.reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_wear_data(data_file, wear_threshold, normalize=False, add_noise=False, sampling_rate=1):\n",
    "    ## Read data\n",
    "    df_raw = pd.read_csv(data_file)\n",
    "\n",
    "    df = downsample(df_raw, sampling_rate)\n",
    "\n",
    "    # Reset index as the downsampling disturbs the index and then PPO.learn() fails. Gives a \"Key error\"\n",
    "    df = df.reset_index(drop=True)\n",
    "    n_points = len(df.index)\n",
    "\n",
    "    # 1. Add white noise for robustness\n",
    "    if add_noise:\n",
    "        df['tool_wear'] = df['tool_wear'] + np.random.normal(0, 1, n_points)/add_noise\n",
    "\n",
    "    # Normalize\n",
    "    if normalize:\n",
    "        WEAR_MIN = df['tool_wear'].min() \n",
    "        WEAR_MAX = df['tool_wear'].max()\n",
    "        # WEAR_THRESHOLD_NORMALIZED = THRESHOLD_FACTOR*(wear_threshold-WEAR_MIN)/(WEAR_MAX-WEAR_MIN)\n",
    "        WEAR_THRESHOLD_NORMALIZED = 0\n",
    "        df_normalized = (df-df.min())/(df.max()-df.min())\n",
    "\n",
    "        # df_normalized['ACTION_CODE'] = np.where(df_normalized['tool_wear'] < WEAR_THRESHOLD_NORMALIZED, 0.0, 1.0)\n",
    "        # print(f'Tool wear data imported ({n_points} records). WEAR_THRESHOLD_NORMALIZED: {WEAR_THRESHOLD_NORMALIZED:4.3f}')\n",
    "\n",
    "        df_train = df_normalized.copy(deep=True)\n",
    "\n",
    "        tool_wear = df_normalized['tool_wear']\n",
    "        action_code_normalized = df_normalized['ACTION_CODE']\n",
    "        action_code = df['ACTION_CODE']\n",
    "        df_train['ACTION_CODE'] = df['ACTION_CODE']\n",
    "    else:\n",
    "        df_train = df.copy(deep=True)\n",
    "        tool_wear = df['tool_wear']\n",
    "        action_code = df['ACTION_CODE']\n",
    "\n",
    "    plt.figure(figsize=(10, 2.5))\n",
    "    plt.plot(tool_wear, linewidth=1)\n",
    "\n",
    "    \n",
    "    if normalize:\n",
    "        plt.plot(action_code_normalized, linewidth=1)\n",
    "        wear_threshold_return = WEAR_THRESHOLD_NORMALIZED\n",
    "        # plt.axhline(y = WEAR_THRESHOLD_NORMALIZED, color = 'r', linestyle = '--', alpha=0.3) \n",
    "    else:\n",
    "        plt.plot(action_code/4, linewidth=1)\n",
    "        wear_threshold_return = wear_threshold\n",
    "        # plt.axhline(y = wear_threshold, color = 'r', linestyle = '--', alpha=0.3) \n",
    "\n",
    "    plt.title(f'Tool wear (IEEE NUAA W1, W2, W3 and W4)')\n",
    "    plt.grid(color='lightgray', linestyle='-', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    return tool_wear, action_code, wear_threshold_return, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Down-sampling. Input data records: 102. Sampling rate: 1. Expected rows 102.    Down-sampled to 102 rows.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool failure time-point: 1833.335\n"
     ]
    }
   ],
   "source": [
    "tool_wear, action_code, WEAR_THRESHOLD_NORMALIZED, df_train = tool_wear_data(\n",
    "    data_file=NUAA_DATA_FILE, wear_threshold = WEAR_THRESHOLD,\n",
    "    normalize=False, add_noise=ADD_NOISE, sampling_rate = SAMPLING_RATE)\n",
    "\n",
    "\n",
    "failure_point = df_train.loc[df_train['ACTION_CODE'] == 1].iloc[0]\n",
    "TOOL_FAILURE_TIME = failure_point['timestamp']\n",
    "print(f'Tool failure time-point: {TOOL_FAILURE_TIME:3.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%b-%Y  %H:%M:%S\")\n",
    "\n",
    "PATH = 'D:/ResearchLab/IRL/BC_for_PdM_July_2024/'\n",
    "# LOG_PATH = f'{PATH}/tensorboard/{now.strftime(\"%d-%b-%Y_%H_%M\")}/'\n",
    "# writer = SummaryWriter(LOG_PATH)\n",
    "# print(f'Tensorboard logging to {LOG_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DEMONSTRATIONS = 10\n",
    "EPISODES = 200 # Train the Expert for N episodes\n",
    "BATCH_SIZE = 16 \n",
    "LEARNING_RATE = int(1e-3)\n",
    "EVALUATION_ROUNDS = 10\n",
    "\n",
    "# Milling tool env.\n",
    "DATA_FILE = 'PHM_C01.csv'\n",
    "R1, R2, R3 = 2.0, -1.0, -20.0\n",
    "WEAR_THRESHOLD = 0.12 # mm\n",
    "THRESHOLD_FACTOR = 1.0\n",
    "ADD_NOISE = 0 # 0=No noise, Low=1e3, High=1e2 \n",
    "BREAKDOWN_CHANCE = 0 # Recommended: 0.05 = 5%\n",
    "MILLING_OPERATIONS_MAX = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating the PdM Milling tool environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool wear data imported (1000 records). WEAR_THRESHOLD_NORMALIZED: 0.574\n"
     ]
    }
   ],
   "source": [
    "## Read tool-wear data\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "WEAR_MIN = df['tool_wear'].min() \n",
    "WEAR_MAX = df['tool_wear'].max()\n",
    "WEAR_THRESHOLD_NORMALIZED = THRESHOLD_FACTOR*(WEAR_THRESHOLD-WEAR_MIN)/(WEAR_MAX-WEAR_MIN)\n",
    "df_normalized = (df-df.min())/(df.max()-df.min())\n",
    "df_normalized['ACTION_CODE'] = np.where(df_normalized['tool_wear'] < WEAR_THRESHOLD_NORMALIZED, 0.0, 1.0)\n",
    "print(f'Tool wear data imported ({len(df.index)} records). WEAR_THRESHOLD_NORMALIZED: {WEAR_THRESHOLD_NORMALIZED:4.3f}')\n",
    "df_train = df_normalized\n",
    "\n",
    "# gym.register(\n",
    "#     id = 'custom/MillingTool-v0',\n",
    "#     entry_point = MillingTool,\n",
    "#     max_episode_steps = MILLING_OPERATIONS_MAX,\n",
    "# )\n",
    "\n",
    "# # Vectorized environment: Use the `make_vec_env` helper function - make sure to pass `post_wrappers=[lambda env, _: RolloutInfoWrapper(env)]`\n",
    "# env_kwargs = {'df':df_train, 'wear_threshold':WEAR_THRESHOLD_NORMALIZED, 'max_operations':MILLING_OPERATIONS_MAX,\n",
    "#                'add_noise':ADD_NOISE, 'breakdown_chance':BREAKDOWN_CHANCE, 'R1':R1, 'R2':R2, 'R3':R3}\n",
    "\n",
    "# mt_venv = make_vec_env(\n",
    "#     'custom/MillingTool-v0',\n",
    "#     env_make_kwargs=env_kwargs,\n",
    "#     rng=np.random.default_rng(),\n",
    "#     n_envs=1,\n",
    "#     post_wrappers=[lambda mt_venv, _: RolloutInfoWrapper(mt_venv)],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time   force_x   force_y   force_z  vibration_x  vibration_y  \\\n",
      "0    0.000000  0.338273  0.642757  0.323310     0.519743     0.594828   \n",
      "1    0.000317  0.340637  0.648475  0.307901     0.469238     0.531250   \n",
      "2    0.000980  0.338581  0.637121  0.320678     0.534435     0.628233   \n",
      "3    0.001412  0.340320  0.652710  0.328161     0.517906     0.600216   \n",
      "4    0.004091  0.333099  0.636294  0.311387     0.543618     0.614224   \n",
      "..        ...       ...       ...       ...          ...          ...   \n",
      "995  0.997378  0.099814  0.487266  0.232261     0.514233     0.245690   \n",
      "996  0.997926  0.250500  0.644055  0.135969     0.564738     0.428879   \n",
      "997  0.998156  0.376461  0.687885  0.629777     0.593205     0.674569   \n",
      "998  0.998387  0.579013  0.834379  0.753528     0.149679     0.517241   \n",
      "999  1.000000  0.324144  0.000000  0.376273     0.280992     0.586207   \n",
      "\n",
      "     vibration_z  acoustic_emission_rms  tool_wear  ACTION_CODE       RUL  \n",
      "0       0.500000               0.021164   0.000000          0.0  1.000000  \n",
      "1       0.456318               0.026455   0.000000          0.0  1.000000  \n",
      "2       0.518721               0.010582   0.000000          0.0  1.000000  \n",
      "3       0.500000               0.010582   0.000000          0.0  1.000000  \n",
      "4       0.514041               0.100529   0.005478          0.0  0.994522  \n",
      "..           ...                    ...        ...          ...       ...  \n",
      "995     0.265991               0.547619   1.000000          1.0  0.000000  \n",
      "996     0.557722               0.780423   1.000000          1.0  0.000000  \n",
      "997     0.459438               0.645503   1.000000          1.0  0.000000  \n",
      "998     0.517161               0.645503   1.000000          1.0  0.000000  \n",
      "999     0.481279               0.084656   1.000000          1.0  0.000000  \n",
      "\n",
      "[1000 rows x 11 columns]\n",
      "\n",
      "\n",
      "** -- NUAA Milling Tool Wear environment. Records 1000 -- **\n",
      "\n",
      "\n",
      "Milling tool environment initiated. Number of records: 1000\n"
     ]
    }
   ],
   "source": [
    "gym.register(\n",
    "    id = 'custom/MillingToolNUAA-v0',\n",
    "    entry_point = MillingToolEnv_NUAA,\n",
    "    max_episode_steps = MILLING_OPERATIONS_MAX,\n",
    ")\n",
    "\n",
    "env_test = gym.make('custom/MillingToolNUAA-v0', df=df_train, max_op_cycles=MILLING_OPERATIONS_MAX, \n",
    "                          tool_failure_thresholds=WEAR_THRESHOLD_NORMALIZED, tool_failure_times=TOOL_FAILURE_TIME)\n",
    "\n",
    "# # Vectorized environment: Use the `make_vec_env` helper function - make sure to pass `post_wrappers=[lambda env, _: RolloutInfoWrapper(env)]`\n",
    "# env_kwargs = {'df':df_train, 'max_op_cycles':MILLING_OPERATIONS_MAX, 'tool_failure_thresholds':WEAR_THRESHOLD_NORMALIZED, \n",
    "#               'tool_failure_times':TOOL_FAILURE_TIME}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mt_venv_nuaa = make_vec_env(\n",
    "    'custom/MillingToolNUAA-v0',\n",
    "    env_make_kwargs=env_kwargs,\n",
    "    rng=np.random.default_rng(),\n",
    "    n_envs=1,\n",
    "    post_wrappers=[lambda mt_venv_nuaa, _: RolloutInfoWrapper(mt_venv_nuaa)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Milling environent \n",
    "- Default method of creating is `env_mt = gym.make('custom/MillingTool-v0')`\n",
    "- This does **not** work with `imitation` IRL\n",
    "- Must create a vectorized env. using `make_vec_env` utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vectorized environment: Use the `make_vec_env` helper function - make sure to pass `post_wrappers=[lambda env, _: RolloutInfoWrapper(env)]`\n",
    "# env_kwargs = {'df':df_train, 'max_op_cycles':MILLING_OPERATIONS_MAX, 'tool_failure_thresholds':WEAR_THRESHOLD_NORMALIZED, \n",
    "#               'tool_failure_times':TOOL_FAILURE_TIME}\n",
    "\n",
    "# mt_venv = make_vec_env(\n",
    "#     'custom/MillingToolNUAA-v0',\n",
    "#     env_make_kwargs=env_kwargs,\n",
    "#     rng=np.random.default_rng(),\n",
    "#     n_envs=1,\n",
    "#     post_wrappers=[lambda mt_venv, _: RolloutInfoWrapper(mt_venv)],\n",
    "# )\n",
    "\n",
    "# # Load the wear data dataframe\n",
    "# # mt_venv.load_df(df=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The \"Human\" Expert (here we create one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expert_a2c = A2C('MlpPolicy', env_mt)\n",
    "# expert_a2c.learn(total_timesteps=EPISODES)\n",
    "EPISODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- RESET -- \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m expert_ppo \u001b[38;5;241m=\u001b[39m PPO(\n\u001b[0;32m      2\u001b[0m     policy \u001b[38;5;241m=\u001b[39m MlpPolicy,\n\u001b[0;32m      3\u001b[0m     env \u001b[38;5;241m=\u001b[39m env_test,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# tensorboard_log=LOG_PATH,\u001b[39;00m\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m \u001b[43mexpert_ppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEPISODES\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:264\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOnPolicyAlgorithm,\n\u001b[0;32m    255\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOnPolicyAlgorithm:\n\u001b[0;32m    262\u001b[0m     iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 264\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:423\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_num_timesteps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:77\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m     76\u001b[0m     maybe_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m---> 77\u001b[0m     obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds[env_idx], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmaybe_options)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: iteration over a 0-d array"
     ]
    }
   ],
   "source": [
    "expert_ppo = PPO(\n",
    "    policy = MlpPolicy,\n",
    "    env = env_test,\n",
    "    # seed = 0,\n",
    "    batch_size = 64,\n",
    "    ent_coef = 0.0,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    n_epochs = 10,\n",
    "    n_steps = 64,\n",
    "    # tensorboard_log=LOG_PATH,\n",
    ")\n",
    "\n",
    "expert_ppo.learn(EPISODES) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check PPO Expert reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward, _ = evaluate_policy(expert_ppo, mt_venv_nuaa, EVALUATION_ROUNDS)\n",
    "print(f'PPO Expert reward: {reward}')\n",
    "\n",
    "# reward, _ = evaluate_policy(expert_a2c, env_mt, 10)\n",
    "# print(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demonstrations from the the Expert\n",
    "\n",
    "- Use the expert to sample some trajectories.\n",
    "- Flatten them to obtain individual transitions for behavior cloning\n",
    "\n",
    "#### Implementation details: \n",
    "- Use `imitation` utilities - Collect 50 episode rollouts, then flatten them to just the transitions that we need for training.\n",
    "- `rollout` function requires a vectorized environment and needs the `RolloutInfoWrapper` around each of the environments\n",
    "- This is why we passed the `post_wrappers` argument to `make_vec_env` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "rollouts = rollout.rollout(\n",
    "    expert_ppo,\n",
    "    mt_venv_nuaa,\n",
    "    rollout.make_sample_until(min_timesteps=None, min_episodes=SAMPLE_DEMONSTRATIONS),\n",
    "    rng = rng,\n",
    ")\n",
    "\n",
    "transitions = rollout.flatten_trajectories(rollouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at what we just generated using those library functions:\n",
    "\n",
    "```print(f\"\"\"The `rollout` function generated a list of {len(rollouts)} {type(rollouts[0])}.\n",
    "After flattening, this list is turned into a {type(transitions)} object containing {len(transitions)} transitions.\n",
    "The transitions object contains arrays for: {', '.join(transitions.__dict__.keys())}.\"\n",
    "\"\"\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "obsvs = []\n",
    "acts = []\n",
    "\n",
    "for n in range(len(rollouts)):\n",
    "    acts.append(transitions.acts[n])\n",
    "    obsvs.append(transitions.obs[n])\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title('Expert Actions')\n",
    "plt.plot(acts)\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.title('Sampled Observations')\n",
    "plt.plot(obsvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we collected our transitions, it's time to set up our behavior cloning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.algorithms import bc\n",
    "from imitation.util import logger as imit_logger\n",
    "\n",
    "# Set new logger\n",
    "tmp_path_irl = f'{PATH}/tensorboard/irl_log/BC/'\n",
    "new_logger_irl = imit_logger.configure(tmp_path_irl, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "\n",
    "bc_trainer = bc.BC(\n",
    "    observation_space=mt_venv.observation_space,\n",
    "    action_space=mt_venv_nuaa.action_space,\n",
    "    demonstrations=transitions,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    rng=rng,\n",
    "    device='cpu',\n",
    "    custom_logger = new_logger_irl\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the untrained policy only gets poor rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_before_training, _ = evaluate_policy(bc_trainer.policy, mt_venv_nuaa, EVALUATION_ROUNDS)\n",
    "print(f\"Reward before training: {reward_before_training: 4.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Behavioural Cloning (BC) based learning from expert demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_trainer.train(n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%b-%Y  %H:%M:%S\")\n",
    "reward_after_training, _ = evaluate_policy(bc_trainer.policy, mt_venv_nuaa, EVALUATION_ROUNDS)\n",
    "\n",
    "print('-'*120)\n",
    "print(' **** IRL with Imitation Libraries and Milling environment ****')\n",
    "print('-'*120)\n",
    "\n",
    "print(dt_string)\n",
    "print(f'Episodes: {EPISODES}')\n",
    "print(f'Rewards Before: {reward_before_training:5.3f} | After: {reward_after_training:5.3f}')\n",
    "# print(f'Training time: {elapsed_time:5.3f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.algorithms import sqil\n",
    "from imitation.util import logger as imit_logger\n",
    "\n",
    "# Set new logger\n",
    "tmp_path_irl = f'{PATH}/tensorboard/irl_log/SQIL/'\n",
    "new_logger_irl = imit_logger.configure(tmp_path_irl, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "\n",
    "sqil_trainer = sqil.SQIL(   \n",
    "    venv = mt_venv_nuaa,\n",
    "    demonstrations = transitions,\n",
    "    policy='MlpPolicy',\n",
    "    # device='cpu',\n",
    "    custom_logger = new_logger_irl\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "reward_before_training, _ = evaluate_policy(sqil_trainer.policy, mt_venv_nuaa, 10)\n",
    "print(f\"Reward before training: {reward_before_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqil_trainer.train(\n",
    "    total_timesteps = 100, # Note: set to 1_000_000 to obtain good results\n",
    ")  \n",
    "reward_after_training, _ = evaluate_policy(sqil_trainer.policy, mt_venv_nuaa, 10)\n",
    "print(f\"Reward after training: {reward_after_training:5.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqil_trainer.train(\n",
    "#     total_timesteps=1_000_000, # Note: set to 1_000_000 to obtain good results\n",
    "# )  \n",
    "# reward_after_training, _ = evaluate_policy(sqil_trainer.policy, mt_venv, 10)\n",
    "# print(f\"Reward after training: {reward_after_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "env = DummyVecEnv([lambda: BaselEnv()])\n",
    "obs = env.reset()\n",
    "\n",
    "for i in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step([action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd378ce8f53beae712f05342da42c6a7612fc68b19bea03b52c7b1cdc8851b5f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
